[{"categories":null,"contents":"As I lack proof of cloud skills working for others I put this together to showcase my skills. You may ask \u0026ldquo;What is Cloud Resume Challenge\u0026rdquo;? let me use a bit Prompt engineering and see what GPT3 says \u0026ldquo;As more and more businesses move to the cloud, they are looking for ways to leverage this new technology to improve their bottom line. One way they are doing this is by challenging their employees to create resumes that are stored in the cloud. The cloud resume challenge is a way for businesses to encourage their employees to create resumes that are stored in the cloud. This way, if an employee leaves the company, their resume is still stored in the cloud and can be accessed by the new employer. This challenge can be used as a way to improve employee retention, as well as to help businesses save money on printing and storing paper resumes. It is also a way to encourage employees to keep their resumes up to date. If you are a business owner or manager, you can encourage your employees to participate in the cloud resume challenge by offering a prize for the best resume. This can be a monetary prize, or it can be something like a free day off. To get started, all you need to do is create a cloud storage account and give your employees access to it. Then, challenge them to create the best resume they can. The sky is the limit!\u0026rdquo; I used this template from this site https://cloudresumechallenge.dev/docs/the-challenge/aws modified it a bit by adding more to it.\nHere are the steps I took with a breakdown\nCertification\nI have finished both the AWS training for Practioner and Solutions Architech I will wait until I am back in the US to take the test HTML CSS\nFor section two and three I decied to learn a markdown complier called Hugo to challenage myself and see how well it generates CSS files using combination of markdown and html Static Website\nThis resume site is static site hosted on S3 container I also created dynamic site the root domain of this one https://www.hitechmadeez.com. This allowed me to practice using Wordpress and keeping it secure and up to date and other AWS severics S3 bucket for offsite image storeage,VPC,Load Balancer,EC2,AMI Image,Snapshots,Cloudfront,WAF. I also setup a mail server I had to setup SMTP relay since most cloud providers do not allow mail servers without special premission. HTTPS\nThis site is secured with CloudFront SSL cert the root domain www is cloudfront cache while dev. and other testing envoirments that I used a lets encrypt and wildcard for mail and sub domains DNS\nThe lamp stack server has its internal DNS for namer server for other sub domains. This and main site is hosted through Route53 Javascript\nI am familar wih javascript I would not say I am fluent in using it yet. It is on my list though Database\nThis site using DynamoDB for counter and few other things\nWorpress site is on mysql API Python Tests Infrastructure as Code Source Control CI/CD (Back end) CI/CD (Front end) Blog post\nThis page will serve as a \u0026ldquo;\u0026ldquo;blog\u0026rdquo;\u0026rdquo; ","permalink":"richard-hitech-resume.netlify.app/projects/creations/cloud-resume-challenge.html","tags":["AWS","CSS","CloudFront","Load Balancer","EC2","S3","WAF"],"title":"Cloud Resume Challenge"},{"categories":null,"contents":"Addressed pretty significant page load performance issue founde in larger deployments. Eliminates uses of intensive backend query, replacing it with an asynchronous API call against a lucene index. This change reduces page load from from 2+ minutes to nearly instant, with an incredibly responsive UI.\n","permalink":"richard-hitech-resume.netlify.app/projects/past-projects/deploy-triggers.html","tags":["Java","jQuery","REST APIs","Bamboo","JSON"],"title":"Atlassian Deployment Triggers"},{"categories":null,"contents":"This talk looked at Liberty Mutual’s transformation to Continuous Integration, Continuous Delivery, and DevOps. For a large, heavily regulated industry, this task can not only be daunting, but viewed by many as impossible. Often, organizations try to reduce the friction through micro-fixes, but Eddie’s team asked how to change the culture to reduce the friction and concluded with the following final points:\nDon’t mandate DevOps. Give employees the chance to master their discipline with examples to set and follow. Favor deep end-to-end accomplishments over broad but incremental steps forward. Focus on taking the right teams far before encouraging broad adoption. Centralize the platforms and tools that your teams shouldn’t be thinking about. Provide foundational services/commodities and let teams stay on purpose. Incorporate contributions from everyone; don’t stifle autonomy. Stay open to new ways of working. Challenge security policies, but respect intentions. Find new ways to enforce concerns without abandoning precaution. ","permalink":"richard-hitech-resume.netlify.app/publications/alldaydevops.html","tags":["DevOps","Continuous Integration","Continuous Delivery","CI/CD pipelines","agile","Culture"],"title":"Organically DevOps: Building Quality and Security into the Software Supply Chain at Liberty Mutual"},{"categories":null,"contents":"Shields.io is a massive library of badges that can be inserted into project README\u0026rsquo;s or websites displaying various statuses (code coverage, health, version, etc). Support for docker was missing the current build health, and was a pretty trivial addition.\n","permalink":"richard-hitech-resume.netlify.app/projects/past-projects/shields-docker.html","tags":["Docker","Rest APIs","JavaScript","node.js","JSON"],"title":"Added Docker Build Status Badge to shields.io"},{"categories":null,"contents":"While adding Structured Data to a client\u0026rsquo;s website I found some example JSON that was invalid. Simple contribution to cleanup the user documentation providing syntactically valid JSON documents.\n","permalink":"richard-hitech-resume.netlify.app/projects/past-projects/schema-org.html","tags":["JSON"],"title":"Schema.org Structured Data documentation fixes"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"richard-hitech-resume.netlify.app/search.html","tags":null,"title":"Search Results"}]